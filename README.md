# YESBUT
This project offers the codes run in the Paper ([Arxiv](https://arxiv.org/pdf/2405.19088))

## Our Goals

We aim to challenge AI systems in their ability to recognize and interpret visual humor, grasp nuances in human behavior, comprehend wordplay, and appreciate cultural references. This understanding can enhance AI's ability to interact with users, generate creative content, and interpret multimedia content more effectively, thereby improving user experience in various applications such as content recommendation systems, virtual assistants, and automated content creation tools.

We collect and annotate images which convey various forms of visual humor and storytelling through simple comic panels. They explore themes such as human behavior, animal antics, and wordplay, often leading to unexpected or ironic conclusions.
<div align='left'><img src="./samples/samples.png"  alt="NAME" width="100%"/></div>
## Dataset

### Data Collection of YES-BUT
- Official YES-BUT Image Links: [Instagram](https://www.instagram.com/_yes_but/?hl=en), [Twitter](https://twitter.com/_yesbut_), Telegram
- Metadata: [json file]()

## Experimental Design

### Experimental Setting
- Sample components: (image, caption, contradiction, philosophy, title)

#### Task 1: Contradiction Generation
- Image Setting: p(contradiction|image)
- Full Setting: p(contradiction|image, caption)
	- oracle caption: written by annotators (upper bound)
 	- system caption: generated by VLM itself

#### Task 2: Title MCQ
- Image Setting: p(title_option|image)
- Full Setting: p(title_option|image, caption)
	- oracle caption: written by annotators (upper bound)
 	- system caption: generated by VLM itself

#### Task 3: Deep Philosophy MCQ
- Image Setting: p(philosophy_option|image)
- Full Setting: p(philosophy_option|image, caption)
	- oracle caption: written by annotators (upper bound)
 	- system caption: generated by VLM itself



